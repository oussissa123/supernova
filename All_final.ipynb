{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Train:  100.0\n",
      "accuracy Test:  76.3893016344725\n",
      "rappel classe 0:  79.03118779031188\n",
      "rappel classe 1:  75.62703427149148\n",
      "rappel classe 0 train:  100.0\n",
      "rappel classe 1 train:  100.0\n",
      "train size:  1093\n",
      "Test size:  20190\n",
      "Train size class 0: 556\n",
      "Train size class 1: 537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import math \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def eliminate(A):\n",
    "    i = 0\n",
    "    for v in A.values:\n",
    "        for a in v:\n",
    "            if math.isnan(a):\n",
    "                A = A.drop([i])\n",
    "                break;\n",
    "        i +=1\n",
    "    return A\n",
    "\n",
    "def load1(path, c1 = 0, rm = {}):\n",
    "    data = eliminate(pd.read_csv(path))\n",
    "    Y = np.array(data['clas'], dtype = 'int') \n",
    "    Y = np.array([0 if y == c1 else 1 for y in Y])\n",
    "    del data['clas']\n",
    "    for b in rm:\n",
    "        for p in rm[b]:\n",
    "            del data[b+\"_\"+str(p)]\n",
    "    X = data.values\n",
    "    return X, Y\n",
    "\n",
    "def accuracy(Y_true, Y_pred):\n",
    "    nb = 0\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_true[i] == Y_pred[i]:\n",
    "            nb += 1\n",
    "    return (nb/len(Y_true))*100\n",
    "def rappel(Y_true, Y_pred, c1 = 0):\n",
    "    nb = 0\n",
    "    total = 0\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_true[i] == c1:\n",
    "            total += 1\n",
    "            if Y_pred[i] == c1:\n",
    "                nb += 1\n",
    "    return (nb/total)*100\n",
    "def display_distrib(Y, path = \"class_distribution.png\"):\n",
    "    plt.hist(Y,alpha=0.8)\n",
    "    plt.title(\"Classes\")\n",
    "    plt.ylabel(\"Fréquences\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "#modele = RandomForestClassifier(n_estimators=300, criterion = 'entropy', max_depth=22, random_state=555) # rm = ['g', 'z', 'r']\n",
    "#modele = DecisionTreeClassifier(criterion='entropy', max_depth=15, random_state = 55555) # ['r', 'g', 'z']\n",
    "#modele = MLPClassifier(hidden_layer_sizes=(128, 512), activation='logistic', solver='sgd', random_state = 5555)#, alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#modele = KNeighborsClassifier(n_neighbors=13)\n",
    "#modele = SVC(C=1.0, kernel='poly', degree = 4, random_state = 5555)\n",
    "#modele = XGBClassifier(max_depth=14, learning_rate=0.8, n_estimators=250, random_state = 55555)\n",
    "\n",
    "#modele = LogisticRegression(penalty='l2', dual=True, tol=0.0001, C=0.009, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=5555, solver='liblinear',max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "#m = DecisionTreeClassifier(criterion='entropy', max_depth=15, random_state = 55555) # ['r', 'g', 'z']\n",
    "#modele = AdaBoostClassifier(base_estimator = m, n_estimators=150, learning_rate=1.0, algorithm='SAMME.R', random_state=5555) # rm = ['r', 'g', 'z']\n",
    "\n",
    "\n",
    "rm = {'r':[0, 1, 2, 3, 4], 'g':[0, 1, 2, 3, 4], 'z':[1], 'i':[1]}\n",
    "path_train = \"data/train_bazin_features.csv\"\n",
    "X, Y = load1(path_train, c1 = 0, rm = rm)#load2(path_train, c1 = 0, c2 = 2)#load2(path_train, c1 = 0, c2 = 30)\n",
    "path_test = \"data/test_bazin_features.csv\"\n",
    "Xt, Yt = load1(path_test, c1 = 0, rm = rm)#load2(path_test, c1 = 0, c2 = 2)\n",
    "\n",
    "modele.fit(X, Y)\n",
    "Y_pred = modele.predict(Xt)\n",
    "Y_ = modele.predict(X)\n",
    "\n",
    "ac_test = accuracy(Yt, Y_pred)\n",
    "ac_train = accuracy(Y, Y_)\n",
    "\n",
    "r0 = rappel(Yt, Y_pred, c1 = 0)\n",
    "r1 = rappel(Yt, Y_pred, c1 = 1)\n",
    "\n",
    "print(\"accuracy Train: \", ac_train)\n",
    "print(\"accuracy Test: \", ac_test)\n",
    "\n",
    "print(\"rappel classe 0: \", r0)\n",
    "print(\"rappel classe 1: \", r1)\n",
    "\n",
    "r2 = rappel(Y, Y_, c1 = 0)\n",
    "r3 = rappel(Y, Y_, c1 = 1)\n",
    "\n",
    "print(\"rappel classe 0 train: \", r2)\n",
    "print(\"rappel classe 1 train: \", r3)\n",
    "\n",
    "#display_distrib(Y, path = \"class_distribution_train.png\")\n",
    "#display_distrib(Y, path = \"class_distribution_test.png\")\n",
    "\n",
    "print(\"train size: \", len(Y))\n",
    "print(\"Test size: \", len(Yt))\n",
    "a, b = 0, 0\n",
    "for y in Y:\n",
    "    if y == 0:\n",
    "        a += 1\n",
    "    else:\n",
    "        b += 1\n",
    "print(\"Train size class 0:\", a)\n",
    "print(\"Train size class 1:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

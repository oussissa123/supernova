{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "300\n",
      "g_flux     21538\n",
      "r_flux     22322\n",
      "i_flux     22503\n",
      "z_flux     18615\n",
      "g_fluxe     6848\n",
      "r_fluxe     3010\n",
      "i_fluxe     4121\n",
      "z_fluxe     3379\n",
      "dtype: int64\n",
      "         g_flux    g_fluxe      i_flux    i_fluxe      r_flux    r_fluxe  \\\n",
      "0     39.432071  34.016879   21.561253  12.821849   17.588945  10.274587   \n",
      "1     11.003387   5.668156   20.996880   3.076891   22.245347   1.937104   \n",
      "2    109.187628  35.101592  129.236273  12.704664  149.590423  10.296427   \n",
      "3     56.208222  27.756921   67.951332  24.654397   36.221442  13.562841   \n",
      "4    150.913177  21.961650   82.606680   8.597849   94.839835   5.022493   \n",
      "5     81.590253  21.858600   69.653518   9.875740   53.810635   5.552028   \n",
      "6     39.591715  21.701772   32.792606   9.992539   30.109327   5.723628   \n",
      "7     41.555263  26.480123   32.659705  24.072549   22.556649  13.064212   \n",
      "8     30.376308  10.021865   58.432971   7.998127   59.890603   3.465707   \n",
      "9     55.064445   8.723854   53.187189   2.263532   48.647779   2.260320   \n",
      "10     1.283370   3.304222    3.686589   0.811145    4.211752   0.611628   \n",
      "11    48.802058   8.112336   33.168311   7.138035   44.100326   2.577405   \n",
      "12    55.700075   6.789861   79.436545   3.355169   95.909495   2.385566   \n",
      "13    95.025663  10.695948  103.910855   4.630960  140.873791   2.513535   \n",
      "14    63.029848  29.984031   57.569874  10.487985   20.722634   8.067782   \n",
      "15    62.972350  39.495824   76.384736  36.262643  100.167382  35.032220   \n",
      "16    50.612589  39.692466   62.191423  36.204943   21.530621  34.096131   \n",
      "17    46.988124  22.525710   69.287991  10.176573   52.160275   5.810329   \n",
      "18    59.744948  39.693658   37.321208  36.190831   68.324748  34.116398   \n",
      "19    22.868620  10.238190   40.555097   4.383859   45.651498   3.632568   \n",
      "20    76.292584  58.671963   18.897678  30.103777   11.881479  10.885992   \n",
      "21    83.701138  12.441860   91.676322   5.777249   93.346864   4.250450   \n",
      "22     2.367775   3.406272   23.665294   1.027053    7.539843   0.734040   \n",
      "23    72.476412  16.201158   39.784921  11.045562   28.952064   7.033068   \n",
      "24    36.000452  34.572900   21.496684  13.096936   15.615307  10.602837   \n",
      "25    35.138051  30.449798   59.648086   9.240569   44.445143   6.946505   \n",
      "26    72.011911  22.222406   42.935237  10.346014   44.153226   5.951724   \n",
      "27    31.678134   4.977630   36.767962   2.413168   45.320848   1.352983   \n",
      "28   115.774480  34.678803  181.018649  12.244209  155.182324   9.486917   \n",
      "29    41.407479  42.527061   75.245329  38.054207   46.560204  36.302109   \n",
      "..          ...        ...         ...        ...         ...        ...   \n",
      "270   10.696389   3.094188   34.164512   0.861640   28.507833   1.005603   \n",
      "271   96.870522  30.799232   83.716578   9.237422   80.317695   6.983567   \n",
      "272   44.184208   9.456635    9.836847   4.788765    9.531787   2.286105   \n",
      "273   88.907077  59.162474   52.079212  31.623556   35.224918  11.134037   \n",
      "274   15.938683   8.622528   18.659971   2.709951   19.472685   2.420152   \n",
      "275   42.681939   3.257796   28.183340   1.105543   37.155884   1.054217   \n",
      "276   55.967913  41.802563   84.055965  37.690760   87.400621  36.014320   \n",
      "277   47.289199  19.741934  104.804113   8.362241  107.000596   3.809977   \n",
      "278   59.924874  61.093352   86.615839  33.601839   55.646016  11.907692   \n",
      "279  145.641552  30.668802  120.007873   8.429281   97.856003   6.662924   \n",
      "280   66.362151   7.002472  150.288247   5.559353  110.112077   2.384898   \n",
      "281   28.573285   8.448017   33.241717   4.797497   31.612927   2.301297   \n",
      "282  107.811933  34.384860  191.947983  11.954427  197.735196  10.333836   \n",
      "283   50.512203  33.962076   86.589095  12.213999   91.013512  10.003693   \n",
      "284   64.364909  42.523084   66.519880  38.032426   44.854345  36.294846   \n",
      "285   72.447117  35.192849   70.962542  12.851091   67.404566  10.214639   \n",
      "286   56.141125  35.390074   83.883658  12.779323   88.289278  10.152353   \n",
      "287   35.980500  22.280783   94.576409   8.686865   98.374121   5.094034   \n",
      "288   91.438696  20.754366  141.689613  12.424007  150.043213  12.373007   \n",
      "289   22.622540   7.313934   20.334270   2.937008   21.186200   2.934374   \n",
      "290  186.726000  22.131298  135.560945   8.559833  173.871291   5.484163   \n",
      "291   68.789699  15.528076   28.385882  10.236943   21.643872   6.685389   \n",
      "292   37.137338  50.428553   31.742239  24.067088   17.737772   9.606250   \n",
      "293   44.484837  22.049159   45.173551  10.294648   56.243651   5.770194   \n",
      "294   13.549591   5.549258   23.427319   2.727449   24.071130   1.317678   \n",
      "295   55.190524  59.153195   40.066248  31.536696   22.609405  11.138522   \n",
      "296   55.303190   9.672231   34.729958   4.200309   24.885777   3.049710   \n",
      "297   78.047227  27.373542   46.127628  24.450513   21.721003  13.172449   \n",
      "298   69.221580  37.908549   47.803437  34.867427   64.602622  34.789808   \n",
      "299   74.081134  27.709558   85.996785  24.774356   66.926698  13.519466   \n",
      "\n",
      "         z_flux    z_fluxe  \n",
      "0     29.082147  10.214136  \n",
      "1     23.697002   1.871438  \n",
      "2     92.772697  10.216090  \n",
      "3     59.938438  37.234735  \n",
      "4     49.790893  11.904691  \n",
      "5     55.009718  11.616234  \n",
      "6     38.709678  11.984335  \n",
      "7     85.701941  36.893365  \n",
      "8     47.772697   5.558016  \n",
      "9     30.960144   2.067382  \n",
      "10    10.903668   3.003628  \n",
      "11    24.424764   2.425741  \n",
      "12    73.475577   2.299168  \n",
      "13    91.187646   2.654047  \n",
      "14    63.702767   3.140295  \n",
      "15    75.501586  19.109135  \n",
      "16    40.435469  18.667525  \n",
      "17    58.706386  12.122524  \n",
      "18    31.213635  18.659462  \n",
      "19    36.479718   9.327930  \n",
      "20    25.487210  10.736059  \n",
      "21    90.003515   5.755536  \n",
      "22    16.826375   0.478086  \n",
      "23    32.428264   4.284043  \n",
      "24    10.718200  10.472026  \n",
      "25    51.288710  11.110537  \n",
      "26    59.953547  11.943553  \n",
      "27    31.500260   1.663049  \n",
      "28   155.012794  10.419857  \n",
      "29    41.918618  20.129787  \n",
      "..          ...        ...  \n",
      "270   22.523140   1.185759  \n",
      "271   68.476426  11.176188  \n",
      "272   18.454665   2.303990  \n",
      "273   31.874689  11.097226  \n",
      "274   24.310807   2.144714  \n",
      "275    6.894789   1.161801  \n",
      "276   62.084696  19.972554  \n",
      "277   83.442617   5.902367  \n",
      "278   67.783922  11.991487  \n",
      "279   80.175136   9.490219  \n",
      "280  149.625879   3.272639  \n",
      "281   20.952554   2.303513  \n",
      "282  126.354790   9.790832  \n",
      "283   76.100550  10.253312  \n",
      "284   76.625351  20.133712  \n",
      "285   60.187498  10.560098  \n",
      "286   82.421570  10.590369  \n",
      "287   78.298271  11.713728  \n",
      "288  116.313613  33.644237  \n",
      "289   30.642043   2.589309  \n",
      "290   94.610429  11.101807  \n",
      "291   21.671179   4.132515  \n",
      "292   19.249740   9.370399  \n",
      "293   53.826030  11.918735  \n",
      "294   20.427482   2.618883  \n",
      "295   31.975992  11.142073  \n",
      "296   46.256089   3.626223  \n",
      "297   67.942578  37.013887  \n",
      "298   42.502410  19.041243  \n",
      "299   61.388314  37.787153  \n",
      "\n",
      "[300 rows x 8 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "def bazin(time, A, B, t0, tfall, trise):\n",
    "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
    "    return A * X + B\n",
    "\n",
    "def lightcurve_fit(time, flux):\n",
    "    scaled_time = time - time.min()\n",
    "    t0 = scaled_time[flux.argmax()]\n",
    "    guess = (0, 0, t0, 40, -5)\n",
    "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
    "    result = least_squares(errfunc, guess, method='lm')\n",
    "    return result.x\n",
    "\n",
    "def predict (x, deg, coef):\n",
    "    p = 1\n",
    "    result = 0\n",
    "    for i in range(deg + 1):\n",
    "        result += p*coef[deg-i]\n",
    "        p = p*x\n",
    "    return result\n",
    "def predicts (x_vect, deg, coef):\n",
    "    result = []\n",
    "    for x in x_vect:\n",
    "        result.append(predict(x, deg, coef))\n",
    "    return result\n",
    "\n",
    "def error(y1, y2):\n",
    "    a = 0\n",
    "    for i in range(len(y1)):\n",
    "        a += (y1[i]-y2[i])**2\n",
    "    return math.sqrt(a)\n",
    "\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "data = None\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "deg = 3\n",
    "errors = pd.Series({'g_flux':0,'r_flux':0,'i_flux':0,'z_flux':0, 'g_fluxe':0,'r_fluxe':0,'i_fluxe':0,'z_fluxe':0})\n",
    "stats = pd.DataFrame(({'g':[],'r':[],'i':[],'z':[]}))\n",
    "l = len(data)\n",
    "erreurs = pd.DataFrame()\n",
    "x1, x21, y11, y21 = None, None, None, None\n",
    "Y, Ye = None, None\n",
    "mie, miv = 1e30000, 1e3000\n",
    "\n",
    "\n",
    "x13, x213, y113, y213 = None, None, None, None\n",
    "Y3, Ye3 = None, None\n",
    "mie3, miv3 = 0, 0\n",
    "\n",
    "a = 0\n",
    "for idx in data:\n",
    "    t = pd.Series()\n",
    "    sd =  pd.Series()#{'g_flux':0,'r_flux':0,'i_flux':0,'z_flux':0, 'g_fluxe':0,'r_fluxe':0,'i_fluxe':0,'z_fluxe':0})\n",
    "    try:\n",
    "        for band in 'griz':\n",
    "            d = data[idx][band]\n",
    "            x_train = np.array(d['mjd'])\n",
    "            t[band] = len(x_train)\n",
    "            x = x_train\n",
    "            #x_train = x_train.reshape(-1, 1)\n",
    "            y_traine = np.array(d['fluxcalerr'])\n",
    "            y_train = np.array(d['fluxcal'])\n",
    "\n",
    "            #fit = lightcurve_fit(x_train, y_train)\n",
    "            #fite = lightcurve_fit(x_train, y_traine)\n",
    "            #v = bazin(stim2, *fit)\n",
    "            #e = bazin(stim2, *fite)\n",
    "            ab = np.polyfit(x_train, y_train, deg = deg)\n",
    "            bb = np.polyfit(x_train, y_traine, deg = deg)\n",
    "            \n",
    "            \"\"\"\n",
    "            #model linear\n",
    "            regr = linear_model.LinearRegression()\n",
    "            regre = linear_model.LinearRegression()\n",
    "            regr.fit(x_train, y_train)\n",
    "            regre.fit(x_train, y_traine)\n",
    "            \"\"\"\n",
    "            #y1, y2 = regr.predict(x_train), regre.predict(x_train)\n",
    "            #y1, y2 = bazin(x_train - x_train.min(),*fit), bazin(x_train - x_train.min(),*fite)\n",
    "            y1, y2 = predicts(x_train, deg, ab), predicts(x_train, deg, bb)\n",
    "            ve = error(y1, y_train)\n",
    "            ee = error(y2, y_traine)\n",
    "            if ve < miv:\n",
    "                x1 = x\n",
    "                y11 = y1\n",
    "                Y = y_train\n",
    "                miv = ve\n",
    "            if ee < mie:\n",
    "                x21 = x\n",
    "                y21 = y2\n",
    "                Ye = y_traine\n",
    "                mie = ee\n",
    "\n",
    "            if ve > miv3:\n",
    "                x13 = x\n",
    "                y113 = y1\n",
    "                Y3 = y_train\n",
    "                miv3 = ve\n",
    "            if ee > mie3:\n",
    "                x213 = x\n",
    "                y213 = y2\n",
    "                Ye3 = y_traine\n",
    "                mie3 = ee   \n",
    "            errors[band+\"_flux\"] = errors[band+\"_flux\"] + ve\n",
    "            errors[band+\"_fluxe\"] = errors[band+\"_fluxe\"] + ee\n",
    "            sd[band+\"_flux\"] = ve\n",
    "            sd[band+\"_fluxe\"] = ee\n",
    "    except:\n",
    "        a = a + 1\n",
    "    stats = stats.append(t, ignore_index = True)\n",
    "    erreurs = erreurs.append(sd, ignore_index = True)\n",
    "    #break\n",
    "print(a)\n",
    "\n",
    "print(l)\n",
    "print(errors) \n",
    "#print(stats)\n",
    "print(erreurs)\n",
    "errors.to_csv(\"errors_poly3.csv\")\n",
    "#stats.to_csv(\"stats.csv\")\n",
    "erreurs.to_csv(\"erreurs_poly3.csv\")\n",
    "\n",
    "\n",
    "plt.plot(x1, Y, 'o')\n",
    "plt.plot(x1, y11)\n",
    "plt.title(band)\n",
    "plt.savefig(\"imgvalue_poly3.png\")\n",
    "plt.show()\n",
    "plt.plot(x21, Ye, 'o')\n",
    "plt.plot(x21, y21)\n",
    "plt.title(band+\"e\")\n",
    "plt.savefig(\"imgerreur_poly3.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x13, Y3, 'o')\n",
    "plt.plot(x13, y113)\n",
    "plt.title(band)\n",
    "plt.savefig(\"imgvaluemax_poly3.png\")\n",
    "plt.show()\n",
    "plt.plot(x213, Ye3, 'o')\n",
    "plt.plot(x213, y213)\n",
    "plt.title(band+\"e\")\n",
    "plt.savefig(\"imgerreurmax_poly3.png\")\n",
    "plt.show()#\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistques:\n",
      "mean: \n",
      "g    21.290000\n",
      "r    20.766667\n",
      "i    20.250000\n",
      "z    19.703333\n",
      "dtype: float64\n",
      "std: \n",
      "g    8.854334\n",
      "r    8.687091\n",
      "i    8.332317\n",
      "z    8.195242\n",
      "dtype: float64\n",
      "erreurs: \n",
      "\n",
      "mean: \n",
      "\n",
      "g_flux     72.284646\n",
      "g_fluxe    23.300466\n",
      "i_flux     75.529439\n",
      "i_fluxe    14.243250\n",
      "r_flux     74.896889\n",
      "r_fluxe    10.531774\n",
      "z_flux     62.541965\n",
      "z_fluxe    11.774975\n",
      "dtype: float64\n",
      "std: \n",
      "\n",
      "g_flux     105.169204\n",
      "g_fluxe     15.355964\n",
      "i_flux      83.016597\n",
      "i_fluxe     12.217352\n",
      "r_flux     102.101572\n",
      "r_fluxe     10.894790\n",
      "z_flux      65.065822\n",
      "z_fluxe     10.350860\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "means = pd.Series()\n",
    "stds = pd.Series()\n",
    "means1 = pd.Series()\n",
    "stds1 = pd.Series()\n",
    "\n",
    "for ind in stats.columns:\n",
    "    means[ind] = np.mean(stats[ind])\n",
    "    stds[ind] = np.std(stats[ind])\n",
    "for ind in erreurs.columns:\n",
    "    means1[ind] = np.mean(erreurs[ind])\n",
    "    stds1[ind] = np.std(erreurs[ind])\n",
    "print(\"statistques:\")\n",
    "print(\"mean: \")\n",
    "print(means)\n",
    "print(\"std: \")\n",
    "print(stds)\n",
    "print(\"erreurs: \\n\")\n",
    "print(\"mean: \\n\")\n",
    "print(means1)\n",
    "print(\"std: \\n\")\n",
    "print(stds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find and display all time and after put the data in same grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "56177.172     55\n",
      "56179.172     56\n",
      "56187.156     62\n",
      "56189.148     63\n",
      "56194.121     68\n",
      "56207.156     78\n",
      "56215.164     83\n",
      "56221.062     86\n",
      "56222.047     88\n",
      "56228.031     92\n",
      "56229.031     92\n",
      "56230.035     94\n",
      "56231.035     95\n",
      "56235.145     96\n",
      "56236.16      98\n",
      "56237.176     99\n",
      "56238.188     99\n",
      "56243.203    102\n",
      "56244.18     103\n",
      "56245.191    104\n",
      "56246.234    104\n",
      "56248.207    105\n",
      "56258.242    112\n",
      "56261.215    111\n",
      "56274.16     121\n",
      "56282.16     122\n",
      "56177.188     55\n",
      "56179.312     56\n",
      "56187.172     62\n",
      "56189.16      63\n",
      "            ... \n",
      "56235.02      75\n",
      "56237.023     75\n",
      "56243.07      79\n",
      "56245.027     80\n",
      "56247.25      80\n",
      "56258.191     82\n",
      "56312.055     78\n",
      "56320.043     76\n",
      "56328.047     72\n",
      "56336.062     68\n",
      "56345.039     60\n",
      "56350.023     56\n",
      "56312.066     78\n",
      "56320.051     76\n",
      "56328.055     72\n",
      "56336.082     68\n",
      "56345.055     60\n",
      "56350.027     56\n",
      "56312.09      78\n",
      "56320.059     76\n",
      "56328.07      72\n",
      "56337.062     68\n",
      "56346.055     59\n",
      "56350.035     56\n",
      "56312.113     78\n",
      "56320.07      76\n",
      "56328.086     72\n",
      "56337.078     68\n",
      "56348.027     59\n",
      "56351.023     56\n",
      "Length: 636, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "filetest = \"data1/des_test_mini.pkl\"\n",
    "\n",
    "data_train = None\n",
    "data_test = None\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "with gzip.open(filetest, 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "result = pd.Series()\n",
    "data = [data_train, data_test]\n",
    "for dd in data:\n",
    "    for idx in dd:\n",
    "        for band in 'griz':\n",
    "            d = dd[idx][band]\n",
    "            x_train = np.array(d['mjd'])\n",
    "            for val in x_train:\n",
    "                try:\n",
    "                    result[str(val)] = result[str(val)] + 1\n",
    "                except:\n",
    "                    result[str(val)] = 1\n",
    "print(len(result)) \n",
    "print(result)\n",
    "np.save(\"data/grid_mini_time\", np.array(result.index, dtype = float))\n",
    "result.to_csv(\"data/grid_mini_time.csv\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok ...\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "def reshape(time):\n",
    "    X = []\n",
    "    for i in time:\n",
    "        X.append([i])\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "def estimate_gaussian(stime, x_train, y_train):\n",
    "    gp = GaussianProcessRegressor()#n_restarts_optimizer=9)\n",
    "    X = reshape(x_train)\n",
    "    gp.fit(X, y_train)\n",
    "    stime = reshape(stime)\n",
    "    return np.array(gp.predict(stime, return_std=False))\n",
    "\n",
    "def bazin(time, A, B, t0, tfall, trise):\n",
    "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
    "    return A * X + B\n",
    "\n",
    "def lightcurve_fit(time, flux):\n",
    "    scaled_time = time - time.min()\n",
    "    t0 = scaled_time[flux.argmax()]\n",
    "    guess = (0, 0, t0, 40, -5)\n",
    "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
    "    result = least_squares(errfunc, guess, method='lm')\n",
    "    return result.x\n",
    "\n",
    "\n",
    "def predict (x, deg, coef):\n",
    "    p = 1\n",
    "    result = 0\n",
    "    for i in range(deg + 1):\n",
    "        result += p*coef[deg-i]\n",
    "        p = p*x\n",
    "    return result\n",
    "def predicts (x_vect, deg, coef):\n",
    "    result = []\n",
    "    for x in x_vect:\n",
    "        result.append(predict(x, deg, coef))\n",
    "    return result\n",
    "\n",
    "timeGrid = \"data/grid_mini_time.npy\"\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "data = None\n",
    "\n",
    "time_values = (np.load(timeGrid))#[0:50]\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "deg = 3\n",
    "result = pd.DataFrame()\n",
    "aaa = 0\n",
    "for idx in data:\n",
    "    loc = pd.Series()\n",
    "    for band in 'griz':\n",
    "        d = data[idx][band]\n",
    "        x_train = np.array(d['mjd'])\n",
    "        y_traine = np.array(d['fluxcalerr'])\n",
    "        y_train = np.array(d['fluxcal'])\n",
    "        ab = np.polyfit(x_train, y_train, deg = deg)\n",
    "        bb = np.polyfit(x_train, y_traine, deg = deg)\n",
    "        value = \"\"\n",
    "        error = \"\"\n",
    "        loc['clas'] = (data[idx]['header'])['type']\n",
    "        for time in time_values:\n",
    "            try:\n",
    "                pos = x_train.tolist().index(time)\n",
    "                value = value+\";\"+str(y_train[pos])\n",
    "                error = error+\";\"+str(y_traine[pos])\n",
    "            except:\n",
    "                Y, Ye= predict(time, deg, ab), predict(time, deg, bb)\n",
    "                value = value+\";\"+str(Y)\n",
    "                error = error+\";\"+str(Ye)\n",
    "        loc[band] = value[1:]\n",
    "        loc[band+\"_err\"] = error[1:]\n",
    "    result = result.append(loc, ignore_index = True)\n",
    "result.to_csv(\"data/train_mini_poly3.csv\", index = False)\n",
    "print(\"ok ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting ...\n",
      "2390700\n",
      "candidates generation ok\n",
      "starting candidates seeking...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "\n",
    "def z_norm(ST = [1, 2, 3, 4, 5]):\n",
    "    mu = np.mean(ST)\n",
    "    std = np.std(ST)\n",
    "     #print(mu, std)\n",
    "    if std == 0:\n",
    "        A = [0 for i in ST]\n",
    "    else:\n",
    "        A = [(st-mu)/std for st in ST]\n",
    "    return np.array(A)\n",
    "\n",
    "def PAA(ST, dim):\n",
    "    coef = dim/len(ST)\n",
    "    vals = []\n",
    "    i = 0\n",
    "    while i<dim:\n",
    "        a = (len(ST)*(i+1))//dim\n",
    "        ci = np.sum([v for v in ST[i:a]])*coef\n",
    "        i = i + 1\n",
    "        vals.append(ci)\n",
    "    return np.array(vals)\n",
    "\n",
    "def  sax (ts, n_pieces = 16, alphabet = 4):\n",
    "    t_al = alphabet\n",
    "    alphabet = []\n",
    "    for i in range(t_al):\n",
    "        alphabet.append(i)\n",
    "    alphabet_sz = len(alphabet)\n",
    "    thrholds = norm.ppf(np.linspace(1./alphabet_sz,\n",
    "                                    1-1./alphabet_sz,\n",
    "                                    alphabet_sz-1))\n",
    "    def translate(ts_values):\n",
    "        return np.asarray([(alphabet[0] if ts_value < thrholds[0]\n",
    "                else (alphabet[-1] if ts_value > thrholds[-1]\n",
    "                      else alphabet[np.where(thrholds <= ts_value)[0][-1]+1]))\n",
    "                           for ts_value in ts_values])\n",
    "    paa_ts = PAA(z_norm(ts), n_pieces)\n",
    "    result = np.apply_along_axis(translate, 0, paa_ts)\n",
    "    return toString(result, \"\")\n",
    "\n",
    "def sax_all(D, dim = 16, word_size = 4):\n",
    "    result = []\n",
    "    for x in D:\n",
    "        result.append(sax(x, dim, word_size))\n",
    "    return np.array(result)\n",
    "\n",
    "def In_Binary_Data(D, Y, dim = 8, word_size = 4, sax_len = 8, band_sax = '10030#1$2$3', band = 'g'):\n",
    "    result = pd.DataFrame()\n",
    "    l = sax_len\n",
    "    print('starting for computing')\n",
    "    ab, ac = 0, 0\n",
    "    for i in range(len(D)):\n",
    "        T = D[i]\n",
    "        a = 0\n",
    "        vect = pd.Series()\n",
    "        if Y[i] == 0:\n",
    "            vect['clas'] = Y[i]\n",
    "            ab = ab + 1\n",
    "        else:\n",
    "            vect['clas'] = 1\n",
    "            ac = ac + 1\n",
    "        for i in range(len(T)-l+1):\n",
    "            x = T[i:i+l]\n",
    "            sa = sax(x, dim, word_size)\n",
    "            tab = band_sax.split('#')\n",
    "            saxc = tab[0]\n",
    "            indexes = np.array(tab[1].split('$'), dtype = int)\n",
    "            #print(indexes)\n",
    "            #print(saxc == '10030')\n",
    "            sa_val = do_projection_one(sa, indexes)\n",
    "            #print(sa_val)\n",
    "            if sa_val == saxc :\n",
    "                a = 1\n",
    "                break\n",
    "        vect[band] = a\n",
    "        result = result.append(vect, ignore_index = True)\n",
    "    print('end ...')\n",
    "    print(ab, ac)\n",
    "    return result\n",
    "def generate_candidates_with_sax(D, Y, max_ = 20, min_ = 10, dim = 8, word_size = 4):\n",
    "    result = []\n",
    "    second = []\n",
    "    l = max_\n",
    "    nbA, nbB = 0, 0\n",
    "    while l>=min_:\n",
    "        for j in range(len(D)):\n",
    "            T = D[j]\n",
    "            a = []\n",
    "            for i in range(len(T)-l+1):\n",
    "                x = T[i:i+l]\n",
    "                sa = sax(x, dim, word_size)\n",
    "                result.append([x, sa])\n",
    "                second.append([sa+\"D\"+str(j), Y[j]])\n",
    "                a.append(sa)\n",
    "\n",
    "            if Y[j] == 0:\n",
    "                nbA = nbA + 1\n",
    "            else:\n",
    "                nbB = nbB + 1\n",
    "        l = l - 1\n",
    "    return result, second, nbA, nbB\n",
    "\n",
    "\n",
    "def read_data(path , band, min_, max_):\n",
    "    all = pd.read_csv(path)\n",
    "    X, Y = [], []\n",
    "    dataX = all[band]\n",
    "    dataY = all[\"clas\"]\n",
    "    for i in range(len(dataX)):\n",
    "        X.append(np.array(dataX[i].split(\";\"), dtype = float))\n",
    "        Y.append(dataY[i])\n",
    "    return X, Y\n",
    "\n",
    "def choise(mask, ra):\n",
    "    l = [a for a in ra]\n",
    "    k = int(mask)\n",
    "    r = []\n",
    "    while k>0 and len(l)>0:\n",
    "        k = k - 1\n",
    "        np.random.shuffle(l)\n",
    "        r.append(int(l[0]))\n",
    "        l = l[1:len(l)]\n",
    "    return np.array(r)\n",
    "\n",
    "def toString(tab, sep = \"$\"):\n",
    "    r = \"\"\n",
    "    for a in range(len(tab)-1):\n",
    "        r = r + str(tab[a]) + sep\n",
    "    r = r+str(tab[len(tab)-1])\n",
    "    return r\n",
    "\n",
    "def do_projection(pop, indexes):\n",
    "    result = []\n",
    "    for c in pop:\n",
    "        d = c[0]\n",
    "        r = \"\"\n",
    "        for i in range(len(d)):\n",
    "            if not (i in indexes):\n",
    "                r = r + str(d[i])\n",
    "        result.append([r, c[1]])\n",
    "    return result\n",
    "\n",
    "def do_projection_one(c, indexes):\n",
    "    r = \"\"\n",
    "    for i in range(len(c)):\n",
    "        if not (i in indexes):\n",
    "            r = r + str(c[i])\n",
    "    return r\n",
    "\n",
    "def get_kbest_candidates(D, mask, tour, nbB, nbA, dim):\n",
    "    is_ok = []\n",
    "    ttt_ = None\n",
    "    Mini = 1e30000\n",
    "    print(\"starting candidates seeking...\")\n",
    "    for t in range(tour):\n",
    "        masks = np.array(choise(mask, range(dim)))\n",
    "        masks.sort()\n",
    "        temp = str(masks)\n",
    "        if temp in is_ok:\n",
    "            continue\n",
    "        else:\n",
    "            is_ok.append(temp)\n",
    "        pjts = do_projection(D, masks)\n",
    "        tab, tabtemp = pd.DataFrame({}),  pd.Series()\n",
    "        all_without = []\n",
    "        for cd in pjts:\n",
    "            try:\n",
    "                tabtemp[cd[0]] = tabtemp[cd[0]] + 1\n",
    "            except:\n",
    "                r = cd[0].split(\"D\")[0]\n",
    "                tabtemp[cd[0]] = 1\n",
    "                all_without.append([r+'#'+toString(masks), cd[1]])\n",
    "        for c in all_without:\n",
    "            e = c[0]\n",
    "            if c[1] == 0:\n",
    "                cla = c[1]\n",
    "            else:\n",
    "                cla = 1\n",
    "            try:\n",
    "                tab[e][cla] = tab[e][cla] + 1\n",
    "            except:\n",
    "                tab[e] = [0,0]\n",
    "                tab[e][cla] = 1\n",
    "        test = 0\n",
    "        for key in tab.columns:\n",
    "            if tab[key][0]<tab[key][1]:\n",
    "                minim = nbB - tab[key][1] + tab[key][0] \n",
    "            elif tab[key][0]>tab[key][1]:\n",
    "                 minim = nbA - tab[key][0] + tab[key][1] \n",
    "            else:\n",
    "                if nbA > nbB:\n",
    "                    minim = nbA\n",
    "                else:\n",
    "                    minim = nbB\n",
    "            if minim < Mini:\n",
    "                ttt_ = key\n",
    "                Mini = minim\n",
    "    st = 'erreur: ' + str(Mini) + ' shapelet: ' + str(ttt_)\n",
    "    print(st)\n",
    "    return [ttt_]\n",
    "def do_mapping(tab_pair, candidates):\n",
    "    all_ = []\n",
    "    for c in candidates:\n",
    "        c_ = c.split(\"#\")\n",
    "        candidate = c_[0]\n",
    "        indexes = np.array(c_[1].split(\"$\"), dtype = int)\n",
    "        for t in tab_pair:\n",
    "             if do_projection_one(t[1], indexes) == candidate:\n",
    "                 all_.append(t[0])\n",
    "                 #print(len(t[0]))\n",
    "    return all_\n",
    "\n",
    "#The main program\n",
    "\n",
    "max_ = 30\n",
    "min_ = 18\n",
    "dim = 8\n",
    "word_size = 4\n",
    "tour = 30\n",
    "mask = 2\n",
    "band = 'r'\n",
    "\n",
    "p = \"data/\"\n",
    "path = \"data/train_mini_poly3.csv\"\n",
    "X, Y = read_data(path,  band = band, min_ = min_, max_ = max_)\n",
    "#In_Binary_Data(X, Y, dim = dim, word_size = word_size, sax_len = 30, band_sax = '3333#4$5$6$7', band = band).to_csv(p+'first_test8.csv', index = False)\n",
    "print(\"starting ...\")\n",
    "result, second, nbA, nbB = generate_candidates_with_sax(X, Y, max_ = max_, min_ = min_, dim = dim, word_size = word_size)\n",
    "print(len(second))\n",
    "print(\"candidates generation ok\")\n",
    "candidates = get_kbest_candidates(second, mask, tour, nbB, nbA, dim)\n",
    "print(\"best candidates finding ok\")\n",
    "cands = do_mapping(result, candidates)\n",
    "print(\"mapping ok\")\n",
    "#print(cands)\n",
    "np.save(p+\"_cand_\"+band, np.array(cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Affichage de la distribution des tailles de series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADrRJREFUeJzt3W+MZXV9x/H3p/ypFmkAGciGZbvYbCymqYuZEhoag6CGViLbBBqJbbbNJtsm2mBqK6tPWpuawIMKfdCYbAGZByoQlO7GGOtmhdgmDToLq4CLWaRb3LLdGStE7QPNwrcP7tkwLjN778zcO/fOj/crIfecM+dyPvmF+czhd885N1WFJGn9+6VxB5AkDYeFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEmWt5sAsvvLA2b968loeUpHXvwIEDP6yqqX77rWmhb968mdnZ2bU8pCSte0n+a5D9nHKRpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNWKgQk9yXpKHkjyT5FCS30lyQZJ9SQ53r+ePOqwkaWmD3in6j8BXq+qmJGcDvwJ8AthfVbcn2QXsAm4bUU6pXdPT4zmud203p+8ZepJfBd4J3ANQVT+vqpeAG4GZbrcZYNuoQkqS+htkyuUtwDzw2SRPJLk7yTnAxVV1DKB7vWiEOSVJfQxS6GcC7wA+U1VXAP9Hb3plIEl2JplNMjs/P7/CmJKkfgYp9KPA0ap6rFt/iF7BH0+yAaB7nVvszVW1u6qmq2p6aqrv0x8lSSvUt9Cr6n+AHyR5a7fpOuC7wF5ge7dtO7BnJAklSQMZ9CqXvwA+113h8hzwp/T+GDyYZAfwPHDzaCJKkgYxUKFX1UFgsWurrhtuHEnSSnmnqCQ1wkKXpEZY6JLUCAtdkhphoUtSIwa9bFFq27gekCUNkWfoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMG+k7RJEeAnwAvAyeqajrJBcADwGbgCPCHVfXiaGJKkvpZzhn6u6pqa1Wd/DbdXcD+qtoC7O/WJUljspoplxuBmW55Bti2+jiSpJUatNAL+FqSA0l2dtsurqpjAN3rRaMIKEkazEBz6MDVVfVCkouAfUmeGfQA3R+AnQCbNm1aQURJ0iAGOkOvqhe61zngYeBK4HiSDQDd69wS791dVdNVNT01NTWc1JKk1+hb6EnOSXLuyWXgvcBTwF5ge7fbdmDPqEJKkvobZMrlYuDhJCf3/3xVfTXJt4AHk+wAngduHl1MSVI/fQu9qp4D3r7I9v8FrhtFKEnS8nmnqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNWLQpy2+fk1P999nVGZnx3dsSeuOZ+iS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1YuBCT3JGkieSfLlbvyzJY0kOJ3kgydmjiylJ6mc5Z+i3AocWrN8B3FlVW4AXgR3DDCZJWp6BCj3JRuB9wN3deoBrgYe6XWaAbaMIKEkazKBn6HcBHwNe6dbfDLxUVSe69aPAJUPOJklahr6FnuQGYK6qDizcvMiutcT7dyaZTTI7Pz+/wpiSpH4GOUO/Gnh/kiPA/fSmWu4Czkty8kumNwIvLPbmqtpdVdNVNT01NTWEyJKkxfQt9Kr6eFVtrKrNwAeAr1fVB4FHgJu63bYDe0aWUpLU12quQ78N+Mskz9KbU79nOJEkSStxZv9dXlVVjwKPdsvPAVcOP5IkaSW8U1SSGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjVjWw7kkNWR6enzHnp0d37Eb5hm6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhrRt9CTvCHJN5N8O8nTST7Zbb8syWNJDid5IMnZo48rSVrKIGfoPwOuraq3A1uB65NcBdwB3FlVW4AXgR2jiylJ6qdvoVfPT7vVs7p/CrgWeKjbPgNsG0lCSdJABppDT3JGkoPAHLAP+D7wUlWd6HY5ClwymoiSpEEMVOhV9XJVbQU2AlcCly+222LvTbIzyWyS2fn5+ZUnlSSd1rKucqmql4BHgauA85Kc/MajjcALS7xnd1VNV9X01NTUarJKkk5jkKtcppKc1y2/EXg3cAh4BLip2207sGdUISVJ/Q3ynaIbgJkkZ9D7A/BgVX05yXeB+5P8PfAEcM8Ic0qS+uhb6FX1HeCKRbY/R28+XZI0AbxTVJIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEIF8Srdeb6enxHXt2dnzHltY5z9AlqREWuiQ1wkKXpEZY6JLUCAtdkhrRt9CTXJrkkSSHkjyd5NZu+wVJ9iU53L2eP/q4kqSlDHLZ4gngo1X1eJJzgQNJ9gF/AuyvqtuT7AJ2AbeNLOk4L6WTpHWg7xl6VR2rqse75Z8Ah4BLgBuBmW63GWDbqEJKkvpb1hx6ks3AFcBjwMVVdQx6pQ9cNOxwkqTBDXynaJI3AV8EPlJVP04y6Pt2AjsBNm3atJKMklozrinUxu9EHugMPclZ9Mr8c1X1pW7z8SQbup9vAOYWe29V7a6q6aqanpqaGkZmSdIiBrnKJcA9wKGq+vSCH+0FtnfL24E9w48nSRrUIFMuVwN/DDyZ5GC37RPA7cCDSXYAzwM3jyaiJGkQfQu9qv4dWGrC/LrhxpEkrZR3ikpSIyx0SWqEX3Axybw7VtIyeIYuSY2w0CWpERa6JDXCQpekRljoktQIr3LRZPHKHmnFPEOXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDWib6EnuTfJXJKnFmy7IMm+JIe71/NHG1OS1M8gZ+j3Adefsm0XsL+qtgD7u3VJ0hj1LfSq+gbwo1M23wjMdMszwLYh55IkLdNK59AvrqpjAN3rRcOLJElaiZF/KJpkZ5LZJLPz8/OjPpwkvW6ttNCPJ9kA0L3OLbVjVe2uqumqmp6amlrh4SRJ/ay00PcC27vl7cCe4cSRJK3UIJctfgH4D+CtSY4m2QHcDrwnyWHgPd26JGmMzuy3Q1XdssSPrhtyFknSKninqCQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktSIvt8pKknNmJ4ez3FnZ9fkMJ6hS1IjLHRJaoSFLkmNsNAlqREWuiQ1YlWFnuT6JN9L8mySXcMKJUlavhUXepIzgH8Cfg94G3BLkrcNK5gkaXlWc4Z+JfBsVT1XVT8H7gduHE4sSdJyrabQLwF+sGD9aLdNkjQGq7lTNItsq9fslOwEdnarP03yvVUc83QuBH44on/3sK2XrOYcvvWS1ZzDlKw2568NstNqCv0ocOmC9Y3AC6fuVFW7gd2rOM5AksxW1Zju612e9ZLVnMO3XrKac7jWKudqply+BWxJclmSs4EPAHuHE0uStFwrPkOvqhNJPgz8K3AGcG9VPT20ZJKkZVnV0xar6ivAV4aUZbVGPq0zROslqzmHb71kNedwrUnOVL3mc0xJ0jrkrf+S1IgmCj3JkSRPJjmYZG2eJD+gJPcmmUvy1IJtFyTZl+Rw93r+ODN2mRbL+bdJ/rsb14NJfn+cGbtMlyZ5JMmhJE8nubXbPlFjepqcEzWmSd6Q5JtJvt3l/GS3/bIkj3Xj+UB34cNYnSbrfUn+c8GYbh13VujdTZ/kiSRf7tZHPqZNFHrnXVW1dQIvYboPuP6UbbuA/VW1BdjfrY/bfbw2J8Cd3bhu7T4zGbcTwEer6nLgKuBD3SMnJm1Ml8oJkzWmPwOuraq3A1uB65NcBdxBL+cW4EVgxxgznrRUVoC/XjCmB8cX8RfcChxasD7yMW2p0CdSVX0D+NEpm28EZrrlGWDbmoZaxBI5J05VHauqx7vln9D7hbmECRvT0+ScKNXz0271rO6fAq4FHuq2j3084bRZJ06SjcD7gLu79bAGY9pKoRfwtSQHujtTJ93FVXUMer/4wEVjznM6H07ynW5KZuxTQwsl2QxcATzGBI/pKTlhwsa0mxo4CMwB+4DvAy9V1Ylul4l5rMepWavq5Jh+qhvTO5P88hgjnnQX8DHglW79zazBmLZS6FdX1TvoPfnxQ0neOe5AjfgM8Ov0/vf2GPAP443zqiRvAr4IfKSqfjzuPEtZJOfEjWlVvVxVW+nd7X0lcPliu61tqsWdmjXJbwIfB34D+G3gAuC2MUYkyQ3AXFUdWLh5kV2HPqZNFHpVvdC9zgEP0/uPcpIdT7IBoHudG3OeRVXV8e4X6BXgn5mQcU1yFr2S/FxVfanbPHFjuljOSR1TgKp6CXiU3pz/eUlO3qey6GM9xmlB1uu76a2qqp8Bn2X8Y3o18P4kR+g9hfZaemfsIx/TdV/oSc5Jcu7JZeC9wFOnf9fY7QW2d8vbgT1jzLKkkwXZ+QMmYFy7uch7gENV9ekFP5qoMV0q56SNaZKpJOd1y28E3k1vvv8R4KZut7GPJyyZ9ZkFf8hDb156rGNaVR+vqo1VtZneI1G+XlUfZA3GdN3fWJTkLfTOyqF35+vnq+pTY4z0C5J8AbiG3lPhjgN/A/wL8CCwCXgeuLmqxvqB5BI5r6E3NVDAEeDPTs5Tj0uS3wX+DXiSV+cnP0FvfnpixvQ0OW9hgsY0yW/R+4DuDHoneA9W1d91v1f305vCeAL4o+4MeGxOk/XrwBS9aY2DwJ8v+PB0rJJcA/xVVd2wFmO67gtdktSz7qdcJEk9FrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY34f8VxKHCn+K3dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'    \\nprint(len(result)) \\nprint(result)\\nnp.save(\"data/grid_mini_time\", np.array(result.index, dtype = float))\\nresult.to_csv(\"data/grid_mini_time.csv\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "filetest = \"data1/des_test_mini.pkl\"\n",
    "\n",
    "data_train = None\n",
    "data_test = None\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "with gzip.open(filetest, 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "result = pd.Series()\n",
    "data = [data_train, data_test]\n",
    "for dd in data:\n",
    "    for idx in dd:\n",
    "        for band in 'griz':\n",
    "            d = dd[idx][band]\n",
    "            x_train = np.array(d['mjd'])\n",
    "            for val in x_train:\n",
    "                try:\n",
    "                    result[str(val)] = result[str(val)] + 1\n",
    "                except:\n",
    "                    result[str(val)] = 1\n",
    "print(len(result)) \n",
    "print(result)\n",
    "np.save(\"data/grid_mini_time\", np.array(result.index, dtype = float))\n",
    "result.to_csv(\"data/grid_mini_time.csv\")\n",
    "\"\"\"\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "filetest = \"data1/des_test_mini.pkl\"\n",
    "\n",
    "data_train = None\n",
    "data_test = None\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "#with gzip.open(filetest, 'rb') as f:\n",
    "    #data_test = pickle.load(f)\n",
    "#result = pd.Series()\n",
    "#data = [data_train, data_test]\n",
    "#for dd in data:\n",
    "r = []\n",
    "for band in 'griz':\n",
    "    temp = []\n",
    "    for idx in data_train:\n",
    "        d = data_train[idx][band]\n",
    "        temp.append(len(np.array(d['mjd'])))\n",
    "    r.append(temp)\n",
    "\n",
    "plt.hist(np.array(r[0]),bins=10,color=\"red\",alpha=0.8)\n",
    "#plt.title(\"Histogramme avec 100 intervalles\")\n",
    "#plt.ylabel(\"Fréquences\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"    \n",
    "print(len(result)) \n",
    "print(result)\n",
    "np.save(\"data/grid_mini_time\", np.array(result.index, dtype = float))\n",
    "result.to_csv(\"data/grid_mini_time.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     559\n",
      "30     89\n",
      "2      55\n",
      "8      45\n",
      "42     35\n",
      "27     34\n",
      "22     23\n",
      "21     22\n",
      "24     20\n",
      "32     17\n",
      "36     14\n",
      "1      13\n",
      "26     13\n",
      "4      11\n",
      "15     11\n",
      "16     10\n",
      "29     10\n",
      "23     10\n",
      "35      9\n",
      "34      8\n",
      "37      7\n",
      "19      7\n",
      "13      7\n",
      "33      6\n",
      "5       6\n",
      "25      6\n",
      "20      6\n",
      "44      5\n",
      "40      5\n",
      "3       5\n",
      "38      4\n",
      "6       4\n",
      "7       4\n",
      "18      4\n",
      "43      3\n",
      "39      3\n",
      "10      2\n",
      "12      2\n",
      "17      2\n",
      "45      2\n",
      "14      2\n",
      "41      1\n",
      "11      1\n",
      "9       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "filename = \"data1/des_train_mini.pkl\"\n",
    "filetest = \"data1/des_test_mini.pkl\"\n",
    "\n",
    "filenamet = \"data1/des_train.pkl\"\n",
    "filetestt = \"data1/des_test.pkl\"\n",
    "\n",
    "data_train = None\n",
    "data_test = None\n",
    "with gzip.open(filenamet, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "r = pd.Series()\n",
    "for idx in data_train:\n",
    "    c = (data_train[idx]['header'])['type']\n",
    "    try:\n",
    "        r[str(c)] = r[str(c)]+1\n",
    "    except:\n",
    "        r[str(c)] = 1\n",
    "#\"\"\"\n",
    "k = r.sort_values(ascending = False)\n",
    "print(k)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "def dist_eucl (s1, s2):\n",
    "    dis = 0\n",
    "    for i in range(len(s1)):\n",
    "        dis += (s1[i]-s2[i])**2\n",
    "    return dis\n",
    "def distance_eucl(ts, shap):\n",
    "    window = len(shap)\n",
    "    dis = dist_eucl(shap, ts[0:window])\n",
    "    for i in range(1,len(ts)-window + 1):\n",
    "        temp = 0\n",
    "        s2 = ts[i:i+window]\n",
    "        j = 0\n",
    "        again = True\n",
    "        while j < len(shap) and again:\n",
    "            temp += (s1[j]-ts[j])**2\n",
    "            if temp>=dis:\n",
    "                again = False\n",
    "            j = j + 1\n",
    "        if again:\n",
    "            dis = temp\n",
    "    return math.sqrt(dis)\n",
    "\n",
    "#Le tab est une matrice de la forme [[distances avec class 0], [distances avec class 1], [distances avec class 2], ..., [distances avec class n]]\n",
    "def gain(tab):\n",
    "    result = []\n",
    "    for x in tab:\n",
    "        result.append(np.mean(x)-np.std(x))\n",
    "    return np.std(result)\n",
    "\n",
    "def generateCandidate(t, l):\n",
    "    result = []\n",
    "    for i in range(len(t)-l+1):\n",
    "        result.append(t[i:i+t])\n",
    "    return result\n",
    "\n",
    "def AreTheSame(shap1, shap2):\n",
    "    if len(shap1)>len(shap2):\n",
    "        dis = distance_eucl(shap1, shap2)\n",
    "    else:\n",
    "        dis = distance_eucl(shap2, shap1)\n",
    "    return (dis == 0)\n",
    "\n",
    "def removeselfSimilar(shapelets):\n",
    "    i = 0\n",
    "    l1 = len(shapelets)-1\n",
    "    while i<l1:\n",
    "        j = i + 1\n",
    "        l2 = len(shapelets)\n",
    "        while j < l2:\n",
    "            if AreTheSame(shapelets[i][0], shapelets[j][0]):\n",
    "                del shapelets[j]\n",
    "                l2 = len(shapelets)\n",
    "            else:\n",
    "                j +=j\n",
    "        i += i\n",
    "        l1 = len(shapelets)-1\n",
    "    return shapelets\n",
    "\n",
    "def findDistances(s, T):\n",
    "    result = {}\n",
    "    for ts in T:\n",
    "        indice = ts[1]\n",
    "        val = distance_eucl(ts[0], s)\n",
    "        try:\n",
    "            result[indice].append(val)\n",
    "        except:\n",
    "            result[indice] = [val]\n",
    "    r = []\n",
    "    for val in result.values():\n",
    "        r.append(val)\n",
    "    np.array(r)\n",
    "\n",
    "#shapelets is in format of [(shap, gain),(), ..., ()]\t\n",
    "def sortByQuality(shapelets):\n",
    "    for i in range(len(shapelets)-1):\n",
    "        for j in range(i+1, len(shapelets)):\n",
    "            if shapelets[i][1]<shapelets[j][1]:\n",
    "                x = shapelets[i]\n",
    "                shapelets[i] = shapelets[j]\n",
    "                shapelets[j] = x\n",
    "    return shapelets\n",
    "\n",
    "def merge(k, kshapelets, shapelets):\n",
    "    if kshapelets == [] :\n",
    "        return np.array(shapelets[0:k]).tolist()\n",
    "    b = 0\n",
    "    result = []\n",
    "    while b < k:\n",
    "        if kshapelets[0][1]<shapelets[0][1]:\n",
    "            result.append(shapelets[0])\n",
    "            del shapelets[0]\n",
    "        else:\n",
    "            result.append(kshapelets[0])\n",
    "            del kshapelets[0]\n",
    "        b += b\n",
    "    return result\n",
    "\n",
    "# T = [[timeserie2, label],[timeserie1, label], ... [timeserien, label]]\n",
    "def ShapeletCachedSelection(T, min, max, k):\n",
    "    kshapelets = []\n",
    "    for t in T:\n",
    "        shapelets = []\n",
    "        for l in range(min, max+1):\n",
    "            W = generateCandidate(t, l)\n",
    "            for s in W:\n",
    "                #Ds format is as the tab(for gain parameter) format \n",
    "                Ds = findDistances(s, T)\n",
    "                shapelets.append((s, gain(Ds)))\n",
    "        shapelets = sortByQuality(shapelets)\n",
    "        shapelets = removeselfSimilar(shapelets)\n",
    "        kshapelets = merge(k, kshapelets, shapelets)\n",
    "    return shapelets\n",
    "\n",
    "\n",
    "def faster(  ):\n",
    "    while data:\n",
    "        index = random.randrange(len(data))\n",
    "        elem = data[index]\n",
    "        # direct deletion, no search needed\n",
    "        del data[index] \n",
    "        process(elem)\n",
    "\n",
    "def choise_randomly10(T):\n",
    "    index = range(len(T))\n",
    "    data = []\n",
    "    rg = range(len(T))\n",
    "    for i in range(len):\n",
    "        ind = random.choice(rg)\n",
    "        data.append(T[ind])\n",
    "        del rg[ind]\n",
    "    return data\n",
    "def addOnShapelets(shapelets, currentShapelets):\n",
    "    result = [x for x in shapelets]\n",
    "    for x in currentShapelets:\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def orderByLength(shapelets):\n",
    "    result = []\n",
    "    for a in shapelets:\n",
    "        b = a[0]\n",
    "        result.append(b)\n",
    "        i = len(result)-2\n",
    "        while i>=0:\n",
    "            if result[i+1]<result[i]:\n",
    "                aa = result[i+1] \n",
    "                result[i+1] = result[i]\n",
    "                result[i] = aa\n",
    "            else:\n",
    "                break;\n",
    "            i +=1\n",
    "    return result\n",
    "def estimateMinAndMax(T):\n",
    "    shapelets = []\n",
    "    length = len(T[0])\n",
    "    for i in range(1,11):\n",
    "        TT = choise_randomly10(T)\n",
    "        currentShapelets = ShapeletCachedSelection(TT, 1, length, 10)\n",
    "        shapelets = addOnShapelets(shapelets, currentShapelets)\n",
    "    shapelets = orderByLength(shapelets)\n",
    "    min_ = shapelets[25]\n",
    "    max_ = shapelets[75]\n",
    "    return min_, max_\n",
    "\n",
    "def get_index(bands, band):\n",
    "    for i in range(len(bands)):\n",
    "        if band == bands[i]:\n",
    "            return i\n",
    "        \n",
    "def load_from_npy(path, band = \"g\", bands = \"griz\"):\n",
    "    D = np.load(path)\n",
    "    T = []\n",
    "    b = get_index(bands, band)\n",
    "    for t in D:\n",
    "        T.append([t[0][b], t[1]])\n",
    "    return T\n",
    "\n",
    "#loading data\n",
    "#T = [[timeserie2, label],[timeserie1, label], ... [timeserien, label]]\n",
    "path = \"/home/peta/ouissa/data2/data/train_mini_poly.npy\"\n",
    "band = \"g\"\n",
    "T = load_from_npy(path, band = band, bands = \"griz\")\n",
    "print(len(T[0][]), T[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        +0.j         -2.08345784+1.75003721j  0.50830767-2.19959008j\n",
      "  0.50830767+2.19959008j -2.08345784-1.75003721j]\n",
      "[ 0.     0.125  0.25   0.375 -0.5   -0.375 -0.25  -0.125]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "serie = [0.5,1.0,0.5,1.0,0.5,1.0,0.5,1.0]\n",
    "#a = np.fft.fft(serie)\n",
    "\n",
    "def normal(T):\n",
    "    std = np.std(T)\n",
    "    if not(std == 0):\n",
    "        mean = np.mean(T)\n",
    "        for i in range(len(T)):\n",
    "            T[i] = (T[i]-mean)/std\n",
    "    return T\n",
    "\n",
    "c=np.fft.fft(normal([1,2,3,45,7]))\n",
    "print(c)\n",
    "print(np.fft.fftfreq(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modèle bazin et interpollation polynomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "def bazin(time, A, B, t0, tfall, trise):\n",
    "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
    "    return A * X + B\n",
    "\n",
    "def lightcurve_fit(time, flux):\n",
    "    scaled_time = time - time.min()\n",
    "    t0 = scaled_time[flux.argmax()]\n",
    "    guess = (0, 0, t0, 40, -5)\n",
    "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
    "    result = least_squares(errfunc, guess, method='lm')\n",
    "    return result.x\n",
    "\n",
    "\n",
    "def predict (x, deg, coef):\n",
    "    p = 1\n",
    "    result = 0\n",
    "    for i in range(deg + 1):\n",
    "        result += p*coef[deg-i]\n",
    "        p = p*x\n",
    "    return result\n",
    "def predicts (x_vect, deg, coef):\n",
    "    result = []\n",
    "    for x in x_vect:\n",
    "        result.append(predict(x, deg, coef))\n",
    "    return result\n",
    "\n",
    "what = \"train\"\n",
    "filename = \"/home/peta/ouissa/data/des_\"+what+\"_mini.pkl\"\n",
    "\n",
    "saving = \"/home/peta/ouissa/data/param/\"+what+\".csv\"\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "deg = 3\n",
    "result = pd.DataFrame()\n",
    "lost = 0\n",
    "for idx in data:\n",
    "    try:\n",
    "        loc = pd.Series()\n",
    "        for band in 'griz':\n",
    "            d = data[idx][band]\n",
    "            x_train = np.array(d['mjd'])\n",
    "            #y_traine = np.array(d['fluxcalerr'])\n",
    "            y_train = np.array(d['fluxcal'])\n",
    "            out1 = np.polyfit(x_train, y_train, deg = deg)\n",
    "            out2 = lightcurve_fit(x_train, y_train)\n",
    "            for i in range(len(out1)):\n",
    "                loc[band+\"_poly_\"+str(i)] = out1[i]\n",
    "            for i in range(len(out2)):\n",
    "                loc[band+\"_exp_\"+str(i)] = out2[i]\n",
    "            #bb = np.polyfit(x_train, y_traine, deg = deg)\n",
    "            loc['clas'] = (data[idx]['header'])['type']\n",
    "        result = result.append(loc, ignore_index = True)\n",
    "    except:\n",
    "    lost = lost + 1\n",
    "print(\"Lost data: |\"lost)\n",
    "result.to_csv(saving, index = False)\n",
    "print(\"ok ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utilisation juste du modèle bazin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "def bazin(time, A, B, t0, tfall, trise):\n",
    "    X = np.exp(-(time - t0) / tfall) / (1 + np.exp((time - t0) / trise))\n",
    "    return A * X + B\n",
    "\n",
    "def lightcurve_fit(time, flux):\n",
    "    scaled_time = time - time.min()\n",
    "    t0 = scaled_time[flux.argmax()]\n",
    "    guess = (0, 0, t0, 40, -5)\n",
    "    errfunc = lambda params: abs(flux - bazin(scaled_time, *params))\n",
    "    result = least_squares(errfunc, guess, method='lm')\n",
    "    return result.x\n",
    "\n",
    "\n",
    "def predict (x, deg, coef):\n",
    "    p = 1\n",
    "    result = 0\n",
    "    for i in range(deg + 1):\n",
    "        result += p*coef[deg-i]\n",
    "        p = p*x\n",
    "    return result\n",
    "def predicts (x_vect, deg, coef):\n",
    "    result = []\n",
    "    for x in x_vect:\n",
    "        result.append(predict(x, deg, coef))\n",
    "    return result\n",
    "\n",
    "what = \"train\"\n",
    "filename = \"/home/peta/ouissa/data/des_\"+what+\".pkl\"\n",
    "\n",
    "saving = \"/home/peta/ouissa/data/param/\"+what+\".csv\"\n",
    "with gzip.open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "deg = 3\n",
    "result = pd.DataFrame()\n",
    "lost = 0\n",
    "for idx in data:\n",
    "    try:\n",
    "        loc = pd.Series()\n",
    "        for band in 'griz':\n",
    "            d = data[idx][band]\n",
    "            x_train = np.array(d['mjd'])\n",
    "            #y_traine = np.array(d['fluxcalerr'])\n",
    "            y_train = np.array(d['fluxcal'])\n",
    "            #out1 = np.polyfit(x_train, y_train, deg = deg)\n",
    "            out2 = lightcurve_fit(x_train, y_train)\n",
    "            #for i in range(len(out1)):\n",
    "                #loc[band+\"_poly_\"+str(i)] = out1[i]\n",
    "            for i in range(len(out2)):\n",
    "                loc[band+\"_exp_\"+str(i)] = out2[i]\n",
    "            #bb = np.polyfit(x_train, y_traine, deg = deg)\n",
    "            loc['clas'] = (data[idx]['header'])['type']\n",
    "        result = result.append(loc, ignore_index = True)\n",
    "    except:\n",
    "    lost = lost + 1\n",
    "print(\"Lost data: |\"lost)\n",
    "result.to_csv(saving, index = False)\n",
    "print(\"ok ...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
